{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"D:\\MachineLearningPrac\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data1['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.iloc[:, 2:].values\n",
    "y = data1.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish pal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Manish pal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu', input_dim=30))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish pal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Manish pal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish pal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "426/426 [==============================] - 0s 872us/step - loss: 0.6926 - accuracy: 0.6080\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.6911 - accuracy: 0.6338\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.6885 - accuracy: 0.6432\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.6845 - accuracy: 0.6995\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.6782 - accuracy: 0.8216\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.6693 - accuracy: 0.8803\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - 0s 23us/step - loss: 0.6564 - accuracy: 0.9178\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.6384 - accuracy: 0.9296\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.6165 - accuracy: 0.9272\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.5866 - accuracy: 0.9343\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.5504 - accuracy: 0.9319\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.5141 - accuracy: 0.9319\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.4668 - accuracy: 0.9319\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.4214 - accuracy: 0.9343\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.3762 - accuracy: 0.9343\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.3320 - accuracy: 0.9366\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.2964 - accuracy: 0.9413\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.2636 - accuracy: 0.9484\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.2395 - accuracy: 0.9460\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.2161 - accuracy: 0.9531\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.1943 - accuracy: 0.9577\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - 0s 23us/step - loss: 0.1816 - accuracy: 0.9624\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.1686 - accuracy: 0.9624\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.1579 - accuracy: 0.9671\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.1493 - accuracy: 0.9671\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.1392 - accuracy: 0.9671\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.1339 - accuracy: 0.9695\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - 0s 35us/step - loss: 0.1266 - accuracy: 0.9695\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.1233 - accuracy: 0.9695\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.1174 - accuracy: 0.9742\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.1135 - accuracy: 0.9718\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.1056 - accuracy: 0.9718\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.1031 - accuracy: 0.9789\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0993 - accuracy: 0.9742\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0946 - accuracy: 0.9742\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0946 - accuracy: 0.9789\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0858 - accuracy: 0.9765\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0879 - accuracy: 0.9789\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0896 - accuracy: 0.9765\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0904 - accuracy: 0.9765\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0855 - accuracy: 0.9789\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0800 - accuracy: 0.9789\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.99 - 0s 21us/step - loss: 0.0826 - accuracy: 0.9789\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0804 - accuracy: 0.9859\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - 0s 24us/step - loss: 0.0770 - accuracy: 0.9859\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0765 - accuracy: 0.9789\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0752 - accuracy: 0.9812\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0706 - accuracy: 0.9836\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0759 - accuracy: 0.9836\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0691 - accuracy: 0.9812\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - 0s 28us/step - loss: 0.0712 - accuracy: 0.9812\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - 0s 23us/step - loss: 0.0689 - accuracy: 0.9836\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0645 - accuracy: 0.9859\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0663 - accuracy: 0.9836\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0690 - accuracy: 0.9859\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0644 - accuracy: 0.9836\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0672 - accuracy: 0.9836\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - 0s 20us/step - loss: 0.0704 - accuracy: 0.9812\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0646 - accuracy: 0.9836\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - 0s 23us/step - loss: 0.0665 - accuracy: 0.9859\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - 0s 23us/step - loss: 0.0665 - accuracy: 0.9836\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0665 - accuracy: 0.9859\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0619 - accuracy: 0.9836\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0634 - accuracy: 0.9859\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0601 - accuracy: 0.9836\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0621 - accuracy: 0.9859\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0664 - accuracy: 0.9836\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0597 - accuracy: 0.9859\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0615 - accuracy: 0.9859\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0617 - accuracy: 0.9836\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0613 - accuracy: 0.9836\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0572 - accuracy: 0.9836\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - 0s 26us/step - loss: 0.0546 - accuracy: 0.9859\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0562 - accuracy: 0.9836\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0600 - accuracy: 0.9836\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0615 - accuracy: 0.9836\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0574 - accuracy: 0.9836\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0536 - accuracy: 0.9859\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0528 - accuracy: 0.9836\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 19us/step - loss: 0.0533 - accuracy: 0.9836\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0536 - accuracy: 0.9836\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0518 - accuracy: 0.9836\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0491 - accuracy: 0.9836\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0512 - accuracy: 0.9836\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - 0s 25us/step - loss: 0.0539 - accuracy: 0.9859\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0514 - accuracy: 0.9859\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0580 - accuracy: 0.9836\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0513 - accuracy: 0.9859\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0501 - accuracy: 0.9836\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0520 - accuracy: 0.9883\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0527 - accuracy: 0.9859\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0516 - accuracy: 0.9836\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0467 - accuracy: 0.9859\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0503 - accuracy: 0.9859\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0518 - accuracy: 0.9836\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0510 - accuracy: 0.9859\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0455 - accuracy: 0.9836\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0490 - accuracy: 0.9859\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0456 - accuracy: 0.9836\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0524 - accuracy: 0.9859\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0495 - accuracy: 0.9836\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0423 - accuracy: 0.9883\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0435 - accuracy: 0.9883\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0453 - accuracy: 0.9906\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0428 - accuracy: 0.9906\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0470 - accuracy: 0.9836\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0418 - accuracy: 0.9906\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - 0s 15us/step - loss: 0.0446 - accuracy: 0.9883\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0421 - accuracy: 0.9883\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0436 - accuracy: 0.9906\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0462 - accuracy: 0.9883\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0415 - accuracy: 0.9906\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0434 - accuracy: 0.9930\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0423 - accuracy: 0.9930\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - 0s 21us/step - loss: 0.0442 - accuracy: 0.9883\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0417 - accuracy: 0.9930\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0398 - accuracy: 0.9906\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0391 - accuracy: 0.9930\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0399 - accuracy: 0.9930\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0425 - accuracy: 0.9906\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0392 - accuracy: 0.9906\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0424 - accuracy: 0.9906\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0391 - accuracy: 0.9930\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0386 - accuracy: 0.9906\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0396 - accuracy: 0.9930\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - 0s 17us/step - loss: 0.0405 - accuracy: 0.9906\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0382 - accuracy: 0.9906\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0390 - accuracy: 0.9883\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0382 - accuracy: 0.9906\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0415 - accuracy: 0.9883\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0383 - accuracy: 0.9930\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0370 - accuracy: 0.9930\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0327 - accuracy: 0.9906\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - 0s 14us/step - loss: 0.0407 - accuracy: 0.9883\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0384 - accuracy: 0.9930\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0354 - accuracy: 0.9930\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0409 - accuracy: 0.9906\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0331 - accuracy: 0.9930\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0464 - accuracy: 0.9906\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0369 - accuracy: 0.9906\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0354 - accuracy: 0.9930\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0363 - accuracy: 0.9930\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0347 - accuracy: 0.9930\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0368 - accuracy: 0.9930\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0371 - accuracy: 0.9930\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0320 - accuracy: 0.9930\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - 0s 16us/step - loss: 0.0344 - accuracy: 0.9906\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - 0s 19us/step - loss: 0.0354 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2194dc9bec8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size=100, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving model to disk\n",
    "pickle.dump(classifier, open(\"ANNPrac1.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Model to compare results\n",
    "ANNPrac1 = pickle.load(open(\"ANNPrac1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
